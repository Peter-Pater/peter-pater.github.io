---
title: "Virtual Reality Telepresence: 360-Degree Video Streaming with Edge-Compute Assisted Static Foveated Compression"
collection: publications
permalink: /publication/vr-telepresence
excerpt: "A 360&deg; virtual reality telepresence system with edge-compute assisted static foveated compression"
date: 2023-10-01
venue: 'IEEE Transactions on Visualization and Computer Graphics'
paperurl: 'https://doi.org/10.1109/TVCG.2023.3320255'
citation: 'Xincheng Huang, James Riddell, and Robert Xiao, "Virtual Reality Telepresence: 360-Degree Video Streaming with Edge-Compute Assisted Static Foveated Compression," in <i>IEEE Transactions on Visualization and Computer Graphics</i>.'
---
<b>Abstract</b>: Real-time communication with immersive 360&deg; video can enable users to be telepresent within a remotely streamed environment. Increasingly, users are shifting to mobile devices and connecting to the Internet via mobile-cellular networks. As the ideal media for 360&deg; videos, some VR headsets now also come with cellular capacity, giving them potential for mobile applications. However, streaming high-quality 360&deg; live video poses challenges for network bandwidth, particularly on cellular connections. To reduce bandwidth requirements, videos can be compressed using viewport-adaptive streaming or foveated rendering techniques. Such approaches require very low latency in order to be effective, which has previously limited their applications on traditional cellular networks. In this work, we demonstrate an end-to-end virtual reality telepresence system that streams âˆ¼6K 360&deg; video over 5G millimeter-wave (mmW) radio. Our use of 5G technologies, in conjunction with mobile edge compute nodes, substantially reduces latency when compared with existing 4G networks, enabling high-efficiency foveated compression over modern cellular networks on par with WiFi. We performed a technical evaluation of our system's visual quality post-compression with peak signal-to-noise ratio (PSNR) and FOVVideoVDP. We also conducted a user study to evaluate users' sensitivity to compressed video. Our findings demonstrate that our system achieves visually indistinguishable video streams while using up to 80% less data when compared with un-foveated video. We demonstrate our video compression system in the context of an immersive, telepresent video calling application.

<!-- <b>Cite:</b>: X. Huang, J. Riddell and R. Xiao, "Virtual Reality Telepresence: 360-Degree Video Streaming with Edge-Compute Assisted Static Foveated Compression," in <i>IEEE Transactions on Visualization and Computer Graphics</i>, doi: <a href="https://doi.org/10.1145/3570343" target="_blank">10.1109/TVCG.2023.3320255</a>. -->

<b>Demo</b>:
<iframe width="560" height="315" src="https://www.youtube.com/embed/osA0-plRdEE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br/>
<b>Talk</b>:
<iframe width="560" height="315" src="https://www.youtube.com/embed/lNYzxqzE3W4?si=z80UabdY05qRw7x_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>